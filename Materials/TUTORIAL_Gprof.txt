*******************************************************************************
*       Tutorial for GNU performance profiler GPROF with GNU C Compiler       *
*******************************************************************************

DESCRIPTION: GPROF is a tool that, among many other things, allows you to see
.            which functions took the biggest percentage of runtime during the
.            execution of a program compiled by GCC (other compilers supported?)
.            and lets you see which functions called which other functions and
.            how many times each function called other functions.

.            For example if DIV() took 95% of the time and SUB() took 94% of the
.            the time with almost all calls to SUB made by DIV, and SUB makes
.            no other significant function calls of its own, then it's pretty
.            clear we have to optimize the workings of SUB() - perhaps vectorize
.            or multithreadify it or replace it with an implementation of a
.            faster algorithm altogether.

USING GPROF:

STEP 1 - add the -pg compiler option to your GCC compile line

STEP 2 - Run the program as usual. Might run a bit slower due to the profiler
.        measuring and collecting performance statistics. This generates a file
.        called gmon.out. 

.        There is currently no way to tell it to generate 
.        this output to a different file. If gmon.out already exists in that
.        directory, it's overwritten with the new runtime performance data.

STEP 3 - Type on the command line:

gprof your_program's_executable > any_output_text_file.txt

.        FOR EXAMPLE:  gprof Client_GUI > profiler_result.txt
.        
.        This will place the performance information we're looking for in the
.        .txt file. 


STEP 4 - Open the .txt file containing performance measurements and read it.


HOW TO READ THE PROFILER RESULTS: 

-----------------------------------------------
                0.00    0.13       2/486         Signature_GENERATE [2]
                0.01   10.49     164/486         bigint_mod_mul [6]
                0.03   20.47     320/486         bigint_mod_pow [3]
[4]     98.1    0.04   31.09     486         bigint_div2 [4]
               23.85    0.83  741375/741377      bigint_sub2 [5]
                5.07    0.00 5191910/5937269     bigint_equate2 [7]
                1.32    0.01 4450049/4450370     bigint_add_fast [8]
                0.01    0.00 2970666/5197520     bigint_compare2 [13]
                0.00    0.00    2430/1487926     bigint_create [11]
                0.00    0.00     972/11131112     bigint_nullify [12]
-----------------------------------------------

The call graph contains blocks like this one. 

Only one function name per block will have a [num] and one floating point number 
on the left hand side - this is the function this particular block is all about.

[num] is just the ID number for that function.

Function names ABOVE it are all the functions that made calls TO this function,
with info on which function called this function how many times.

Function names BELOW it are all functions that this function itself called, with
info on how many of the total calls to each of these functions THIS function
made. 

The floating point number is percentage of the total time the program spent
in this function AND THE FUNCTIONS IT CALLED!!! This second part is important:

Because it might be saying 98.1% of TOTAL program runtime for DIV2() here,
but it later turned out (by further reading the call graph) that:
- 18% of that same total time was spent in EQUATE()
- 76% of that same total time was spent in SUBTRACT()

And the call graph showed that DIV2() is in fact the primary caller of these
two functions, this is even visible from DIV's call block shown here.

The conclusion was that even tho it says 98.1% of the total time spent in DIV()
it turns out DIV() itself spends most of this time inside the workings of 
SUBTRACT() and EQUATE(), so the targets of any performance boosting efforts 
ought to be put toward improving the workings of the subtraction algorithm
and the implementation of making one big number equal to another big number, or
finding ways (possibly by using entitely different faster algorithms altogether)
to avoid these two functions being called that much.

